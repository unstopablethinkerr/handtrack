<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face & Hand Tracking with Virtual Gifts</title>
    <script src="aframe.min.js"></script>
    <script src="handtrack.min.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
        }
        #video {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
            z-index: -1;
        }
        #canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }
        #resetButton {
            position: fixed;
            bottom: 10px;
            left: 10px;
            background-color: #ff6666;
            color: white;
            border: none;
            border-radius: 5px;
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <video id="video" autoplay></video>
    <canvas id="canvas"></canvas>
    <button id="resetButton">Reset</button>

    <a-scene embedded>
        <a-entity id="box1" gltf-model="treasure_box.glb" position="-1 0 -3"></a-entity>
        <a-entity id="box2" gltf-model="treasure_box.glb" position="0 0 -3"></a-entity>
        <a-entity id="box3" gltf-model="treasure_box.glb" position="1 0 -3"></a-entity>
    </a-scene>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');
        const resetButton = document.getElementById('resetButton');

        const modelParams = {
            flipHorizontal: true,
            imageScaleFactor: 0.6,
            maxNumBoxes: 5,
            iouThreshold: 0.5,
            scoreThreshold: 0.7,
        };

        let model;

        const startTracking = async () => {
            model = await handTrack.load(modelParams);
            handTrack.startVideo(video).then(status => {
                if (status) {
                    navigator.getUserMedia(
                        { video: {} },
                        stream => {
                            video.srcObject = stream;
                            trackHandsAndFace();
                        },
                        err => console.log(err)
                    );
                }
            });
        };

        const trackHandsAndFace = () => {
            setInterval(async () => {
                const predictions = await model.detect(video);
                context.clearRect(0, 0, canvas.width, canvas.height);
                model.renderPredictions(predictions, canvas, context, video);

                predictions.forEach(prediction => {
                    const { bbox, label } = prediction;
                    const [x, y, width, height] = bbox;

                    // Highlight face or hand
                    if (label === 'face' || label === 'hand') {
                        context.strokeStyle = 'green';
                        context.lineWidth = 4;
                        context.strokeRect(x, y, width, height);

                        // If hand is near a box, reveal the gift
                        if (label === 'hand' && width > 100) { // Example proximity check
                            const box = document.querySelector(`#box${Math.ceil(Math.random() * 3)}`);
                            box.setAttribute('gltf-model', 'gift0.glb');
                        }
                    }
                });
            }, 100);
        };

        resetButton.addEventListener('click', () => {
            window.location.reload();
        });

        startTracking();
    </script>
</body>
</html>